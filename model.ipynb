{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>categorical_sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S   \n",
       "1         1       1  female  38.0      1      0  71.2833        C   \n",
       "2         1       3  female  26.0      0      0   7.9250        S   \n",
       "3         1       1  female  35.0      1      0  53.1000        S   \n",
       "4         0       3    male  35.0      0      0   8.0500        S   \n",
       "\n",
       "   embark_town  alone  categorical_sex  \n",
       "0            2      0                1  \n",
       "1            0      0                0  \n",
       "2            2      1                0  \n",
       "3            2      0                0  \n",
       "4            2      1                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from acquire import new_get_titanic_data\n",
    "from titanic_model_setup import prep_titanic\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# using functions from prep and aqcuire to create titanic dataframe\n",
    "# PLEASE NOTE: a new prep file was created for this exercise in order to avoid altering the\n",
    "# contents of the original file (as their requirements differ slighltly)\n",
    "# new file is named 'titanic_model_setup'\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "\n",
    "# display first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 2) , X_validate:  (214, 2) , X_test:  (179, 2)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "X = df[['pclass','fare']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by defining your baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    302\n",
       "1    196\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with class to use for baseline\n",
    "# 0 = did not survive | 1 = survived\n",
    "# since there are less survivors than deceased, not survived will be baseline\n",
    "y_train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline\n",
       "689       1         0\n",
       "84        1         0\n",
       "738       0         0\n",
       "441       0         0\n",
       "643       1         0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe using y_train (survived) data\n",
    "models = pd.DataFrame(y_train)\n",
    "# adding column that will hold baseline values (0)\n",
    "models['baseline'] = 0\n",
    "# renaming first column\n",
    "models.columns = ['actual','baseline']\n",
    "# displaying results\n",
    "models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model is 61.0% accurate\n"
     ]
    }
   ],
   "source": [
    "# calculating baseline accuracy via creating boolean mask that holds true for rows where the \n",
    "# baseline matches the actual value\n",
    "# mean tells use the % of rows where this occured, ie. % of rows where baseline model was correct\n",
    "baseline_accuracy = (models.baseline == models.actual).mean()\n",
    "\n",
    "# printing results, baseline had accuracy of 61%\n",
    "print(f'The baseline model is {round(baseline_accuracy,2) * 100}% accurate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create another model that includes age in addition to fare and pclass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 3) , X_validate:  (214, 3) , X_test:  (179, 3)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "# adding age this time\n",
    "X = df[['pclass','fare', 'age']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# importing imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating logistic regression object\n",
    "logit_1 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training data\n",
    "logit_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.94438149  0.00314466 -0.02819317]]\n",
      "Intercept: \n",
      " [2.41877072]\n"
     ]
    }
   ],
   "source": [
    "# printing model coefficients and intercept \n",
    "print('Coefficient: \\n', logit_1.coef_)\n",
    "print('Intercept: \\n', logit_1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate whether or not a person would survive based on the training data\n",
    "y_pred = logit_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p of person surviving\n",
    "y_pred_proba = logit_1.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259  43]\n",
      " [101  95]]\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78       302\n",
      "           1       0.69      0.48      0.57       196\n",
      "\n",
      "    accuracy                           0.71       498\n",
      "   macro avg       0.70      0.67      0.68       498\n",
      "weighted avg       0.71      0.71      0.70       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report to see details of model performance\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does this model perform better than your previous one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Yes, this model has an accuracy of 71%, this is 10% higher than the baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 4) , X_validate:  (214, 4) , X_test:  (179, 4)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "# adding age and sex this time\n",
    "X = df[['pclass','fare', 'age', 'categorical_sex']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# importing imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating logistic regression object\n",
    "logit_2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training data\n",
    "logit_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.12616011e+00  1.32701409e-04 -2.12849959e-02 -2.39973517e+00]]\n",
      "Intercept: \n",
      " [4.18183443]\n"
     ]
    }
   ],
   "source": [
    "# printing model coefficients and intercept \n",
    "print('Coefficient: \\n', logit_2.coef_)\n",
    "print('Intercept: \\n', logit_2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate whether or not a person would survive based on the training data\n",
    "y_pred = logit_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p of person surviving\n",
    "y_pred_proba = logit_2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246  56]\n",
      " [ 53 143]]\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       302\n",
      "           1       0.72      0.73      0.72       196\n",
      "\n",
      "    accuracy                           0.78       498\n",
      "   macro avg       0.77      0.77      0.77       498\n",
      "weighted avg       0.78      0.78      0.78       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report to see details of model performance\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 5) , X_validate:  (214, 5) , X_test:  (179, 5)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "# adding age, sex and whether the passenger was alone this time\n",
    "X = df[['pclass','fare', 'age', 'categorical_sex', 'alone']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# importing imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 3 different logistic regression objects with different solver arguments\n",
    "# Note: models 4 and 5 will be used for upcoming question # 5\n",
    "logit_3 = LogisticRegression(solver = 'lbfgs')\n",
    "logit_4 = LogisticRegression(solver = 'liblinear')\n",
    "logit_5 = LogisticRegression(solver = 'newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting models to training data \n",
    "# Note: models 4 and 5 will be used for upcoming question # 5\n",
    "logit_3.fit(X_train, y_train)\n",
    "logit_4.fit(X_train, y_train)\n",
    "logit_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.12726009e+00 -3.21796518e-04 -2.03922298e-02 -2.35677691e+00\n",
      "  -2.08399581e-01]]\n",
      "Intercept: \n",
      " [4.26875038]\n"
     ]
    }
   ],
   "source": [
    "# printing model coefficients and intercept \n",
    "print('Coefficient: \\n', logit_3.coef_)\n",
    "print('Intercept: \\n', logit_3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate whether or not a person would survive based on the training data\n",
    "y_pred = logit_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p of person surviving\n",
    "y_pred_proba = logit_3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[251  51]\n",
      " [ 56 140]]\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       302\n",
      "           1       0.73      0.71      0.72       196\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.77      0.77       498\n",
      "weighted avg       0.78      0.79      0.78       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report to see details of model performance\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3:\n",
      "Accuracy: 0.80\n",
      "[[114  19]\n",
      " [ 23  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       133\n",
      "           1       0.75      0.72      0.73        81\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.79      0.79      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n",
      "Model 4:\n",
      "Accuracy: 0.81\n",
      "[[115  18]\n",
      " [ 23  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       133\n",
      "           1       0.76      0.72      0.74        81\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.80      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n",
      "Model 5:\n",
      "Accuracy: 0.80\n",
      "[[114  19]\n",
      " [ 23  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       133\n",
      "           1       0.75      0.72      0.73        81\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.79      0.79      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluating models on sample data\n",
    "y_pred_3 = logit_3.predict(X_validate)\n",
    "y_pred_4 = logit_4.predict(X_validate)\n",
    "y_pred_5 = logit_5.predict(X_validate)\n",
    "\n",
    "# printing accuracy, confusion matrix, and classification report for model 3\n",
    "print(\"Model 3:\")\n",
    "print('Accuracy: {:.2f}'.format(logit_3.score(X_validate, y_validate)))\n",
    "print(confusion_matrix(y_validate, y_pred_3))\n",
    "print(classification_report(y_validate, y_pred_3))\n",
    "\n",
    "# printing accuracy, confusion matrix, and classification report for model 4\n",
    "print(\"Model 4:\")\n",
    "print('Accuracy: {:.2f}'.format(logit_4.score(X_validate, y_validate)))\n",
    "print(confusion_matrix(y_validate, y_pred_4))\n",
    "print(classification_report(y_validate, y_pred_4))\n",
    "\n",
    "# printing accuracy, confusion matrix, and classification report for model 5\n",
    "print(\"Model 5:\")\n",
    "print('Accuracy: {:.2f}'.format(logit_5.score(X_validate, y_validate)))\n",
    "print(confusion_matrix(y_validate, y_pred_5))\n",
    "print(classification_report(y_validate, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Model 4 is ~1% more accurate than models 3 and 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model 4 on train, validate and test data\n",
    "y_pred_4_train = logit_4.predict(X_train)\n",
    "y_pred_4_val = logit_4.predict(X_validate)\n",
    "y_pred_4_test = logit_4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Model 4 applied to train data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       302\n",
      "           1       0.72      0.68      0.70       196\n",
      "\n",
      "    accuracy                           0.77       498\n",
      "   macro avg       0.76      0.75      0.76       498\n",
      "weighted avg       0.77      0.77      0.77       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report for model 4 vs train data \n",
    "print('Classification report of Model 4 applied to train data\\n')\n",
    "print(classification_report(y_train, y_pred_4_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Model 4 applied to validate data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       133\n",
      "           1       0.76      0.72      0.74        81\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.80      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report for model 4 vs validate data \n",
    "print('Classification report of Model 4 applied to validate data\\n')\n",
    "print(classification_report(y_validate, y_pred_4_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Model 4 applied to test data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       114\n",
      "           1       0.73      0.71      0.72        65\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report for model 4 vs test data \n",
    "print('Classification report of Model 4 applied to test data\\n')\n",
    "print(classification_report(y_test, y_pred_4_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Model 4 showcased higher accuracy when applied to the validate and test data than it did when\n",
    "# it was applied to the train data. Overall it had the highest accuracy on the validate data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 3) , X_validate:  (214, 3) , X_test:  (179, 3)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "\n",
    "# declaring which columns will be included in X and y\n",
    "# adding age, sex and whether the passenger was alone this time\n",
    "X = df[['fare','categorical_sex', 'pclass']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing decision tree function\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# setting depth and state for function\n",
    "clf = DecisionTreeClassifier(max_depth = 1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making predictions on whether passengers survived\n",
    "y_pred_1 = clf.predict(X_train)\n",
    "y_pred_1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26404494, 0.73595506],\n",
       "       [0.26404494, 0.73595506],\n",
       "       [0.796875  , 0.203125  ],\n",
       "       [0.796875  , 0.203125  ],\n",
       "       [0.796875  , 0.203125  ]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities of survival\n",
    "y_pred_1_proba = clf.predict_proba(X_train)\n",
    "y_pred_1_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# printing accuracy of model 1\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255,  47],\n",
       "       [ 65, 131]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating confusion matrix\n",
    "confusion_matrix(y_train, y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       302\n",
      "           1       0.74      0.67      0.70       196\n",
      "\n",
      "    accuracy                           0.78       498\n",
      "   macro avg       0.77      0.76      0.76       498\n",
      "weighted avg       0.77      0.78      0.77       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report\n",
    "print(classification_report(y_train, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables for true pos, true negative, false pos, false neg\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1 is 0.7751004016064257\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Accuracy of model 1 is',accuracy) # overall accuracy, positive and negative predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall aka true positive rate of model 1 is 0.6683673469387755\n"
     ]
    }
   ],
   "source": [
    "# calculating recall\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Recall aka true positive rate of model 1 is',recall) # aka true positive rate aka sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative rate of model 1 is 0.8443708609271523\n"
     ]
    }
   ],
   "source": [
    "# calculating specificity\n",
    "specificity = tn / (tn + fp) \n",
    "\n",
    "# displaying results\n",
    "print('True negative rate of model 1 is',specificity) # aka true negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of model 1 is 0.7005347593582888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculating f score\n",
    "f1 = f1_score(y_train, y_pred_1)\n",
    "\n",
    "# displaying results\n",
    "print('F1 score of model 1 is',f1) # the mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of model 1 is 0.7359550561797753\n"
     ]
    }
   ],
   "source": [
    "# calculating precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# displaying results\n",
    "print('precision of model 1 is',precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate of model 1 is 0.15562913907284767\n"
     ]
    }
   ],
   "source": [
    "# calculating false positive rate\n",
    "fallout = fp / (fp + tn)\n",
    "\n",
    "# displaying results\n",
    "print('False positive rate of model 1 is',fallout) # false positive rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negative rate of model 1 is 0.33163265306122447\n"
     ]
    }
   ],
   "source": [
    "# calculating false negative rate\n",
    "miss_rate = fn / (fn + tp)\n",
    "\n",
    "# displaying results\n",
    "print('False negative rate of model 1 is',miss_rate) # false negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support values of model 1 are [302 196]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# calculating support in addition to other values\n",
    "p,r,f,support = precision_recall_fscore_support(y_train, y_pred_1)\n",
    "\n",
    "# displaying support\n",
    "print('support values of model 1 are',support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting depth and state for function (increasing depth to 3)\n",
    "clf = DecisionTreeClassifier(max_depth = 3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting whether each passenger survives or not\n",
    "y_pred_2 = clf.predict(X_train)\n",
    "y_pred_2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01587302, 0.98412698],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.93684211, 0.06315789],\n",
       "       [0.81699346, 0.18300654],\n",
       "       [0.81699346, 0.18300654]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of survival for each passenger\n",
    "y_pred_2_proba = clf.predict_proba(X_train)\n",
    "y_pred_2_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# printing accuracy of model 2\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[264,  38],\n",
       "       [ 67, 129]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating confusion matrix\n",
    "confusion_matrix(y_train, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       302\n",
      "           1       0.77      0.66      0.71       196\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.79      0.77      0.77       498\n",
      "weighted avg       0.79      0.79      0.79       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report\n",
    "print(classification_report(y_train, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
