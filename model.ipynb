{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>categorical_sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S   \n",
       "1         1       1  female  38.0      1      0  71.2833        C   \n",
       "2         1       3  female  26.0      0      0   7.9250        S   \n",
       "3         1       1  female  35.0      1      0  53.1000        S   \n",
       "4         0       3    male  35.0      0      0   8.0500        S   \n",
       "\n",
       "   embark_town  alone  categorical_sex  \n",
       "0            2      0                1  \n",
       "1            0      0                0  \n",
       "2            2      1                0  \n",
       "3            2      0                0  \n",
       "4            2      1                1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from acquire import new_get_titanic_data\n",
    "from titanic_model_setup import prep_titanic\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# using functions from prep and aqcuire to create titanic dataframe\n",
    "# PLEASE NOTE: a new prep file was created for this exercise in order to avoid altering the\n",
    "# contents of the original file (as their requirements differ slighltly)\n",
    "# new file is named 'titanic_model_setup'\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "\n",
    "# display first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 2) , X_validate:  (214, 2) , X_test:  (179, 2)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "X = df[['pclass','fare']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by defining your baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    302\n",
       "1    196\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with class to use for baseline\n",
    "# 0 = did not survive | 1 = survived\n",
    "# since there are less survivors than deceased, not survived will be baseline\n",
    "y_train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline\n",
       "689       1         0\n",
       "84        1         0\n",
       "738       0         0\n",
       "441       0         0\n",
       "643       1         0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe using y_train (survived) data\n",
    "models = pd.DataFrame(y_train)\n",
    "# adding column that will hold baseline values (0)\n",
    "models['baseline'] = 0\n",
    "# renaming first column\n",
    "models.columns = ['actual','baseline']\n",
    "# displaying results\n",
    "models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model is 61.0% accurate\n"
     ]
    }
   ],
   "source": [
    "# calculating baseline accuracy via creating boolean mask that holds true for rows where the \n",
    "# baseline matches the actual value\n",
    "# mean tells use the % of rows where this occured, ie. % of rows where baseline model was correct\n",
    "baseline_accuracy = (models.baseline == models.actual).mean()\n",
    "\n",
    "# printing results, baseline had accuracy of 61%\n",
    "print(f'The baseline model is {round(baseline_accuracy,2) * 100}% accurate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create another model that includes age in addition to fare and pclass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 3) , X_validate:  (214, 3) , X_test:  (179, 3)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "# adding age this time\n",
    "X = df[['pclass','fare', 'age']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# importing imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating logistic regression object\n",
    "logit_1 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training data\n",
    "logit_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.94438149  0.00314466 -0.02819317]]\n",
      "Intercept: \n",
      " [2.41877072]\n"
     ]
    }
   ],
   "source": [
    "# printing model coefficients and intercept \n",
    "print('Coefficient: \\n', logit_1.coef_)\n",
    "print('Intercept: \\n', logit_1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate whether or not a person would survive based on the training data\n",
    "y_pred = logit_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p of person surviving\n",
    "y_pred_proba = logit_1.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259  43]\n",
      " [101  95]]\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78       302\n",
      "           1       0.69      0.48      0.57       196\n",
      "\n",
      "    accuracy                           0.71       498\n",
      "   macro avg       0.70      0.67      0.68       498\n",
      "weighted avg       0.71      0.71      0.70       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report to see details of model performance\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does this model perform better than your previous one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Yes, this model has an accuracy of 71%, this is 10% higher than the baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 4) , X_validate:  (214, 4) , X_test:  (179, 4)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "# adding age and sex this time\n",
    "X = df[['pclass','fare', 'age', 'categorical_sex']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# importing imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating logistic regression object\n",
    "logit_2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training data\n",
    "logit_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.12616011e+00  1.32701409e-04 -2.12849959e-02 -2.39973517e+00]]\n",
      "Intercept: \n",
      " [4.18183443]\n"
     ]
    }
   ],
   "source": [
    "# printing model coefficients and intercept \n",
    "print('Coefficient: \\n', logit_2.coef_)\n",
    "print('Intercept: \\n', logit_2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate whether or not a person would survive based on the training data\n",
    "y_pred = logit_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p of person surviving\n",
    "y_pred_proba = logit_2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246  56]\n",
      " [ 53 143]]\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       302\n",
      "           1       0.72      0.73      0.72       196\n",
      "\n",
      "    accuracy                           0.78       498\n",
      "   macro avg       0.77      0.77      0.77       498\n",
      "weighted avg       0.78      0.78      0.78       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report to see details of model performance\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 5) , X_validate:  (214, 5) , X_test:  (179, 5)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "# adding age, sex and whether the passenger was alone this time\n",
    "X = df[['pclass','fare', 'age', 'categorical_sex', 'alone']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# importing imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 3 different logistic regression objects with different solver arguments\n",
    "# Note: models 4 and 5 will be used for upcoming question # 5\n",
    "logit_3 = LogisticRegression(solver = 'lbfgs')\n",
    "logit_4 = LogisticRegression(solver = 'liblinear')\n",
    "logit_5 = LogisticRegression(solver = 'newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting models to training data \n",
    "# Note: models 4 and 5 will be used for upcoming question # 5\n",
    "logit_3.fit(X_train, y_train)\n",
    "logit_4.fit(X_train, y_train)\n",
    "logit_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.12726009e+00 -3.21796518e-04 -2.03922298e-02 -2.35677691e+00\n",
      "  -2.08399581e-01]]\n",
      "Intercept: \n",
      " [4.26875038]\n"
     ]
    }
   ],
   "source": [
    "# printing model coefficients and intercept \n",
    "print('Coefficient: \\n', logit_3.coef_)\n",
    "print('Intercept: \\n', logit_3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate whether or not a person would survive based on the training data\n",
    "y_pred = logit_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p of person surviving\n",
    "y_pred_proba = logit_3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[251  51]\n",
      " [ 56 140]]\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       302\n",
      "           1       0.73      0.71      0.72       196\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.77      0.77       498\n",
      "weighted avg       0.78      0.79      0.78       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report to see details of model performance\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3:\n",
      "Accuracy: 0.80\n",
      "[[114  19]\n",
      " [ 23  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       133\n",
      "           1       0.75      0.72      0.73        81\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.79      0.79      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n",
      "Model 4:\n",
      "Accuracy: 0.81\n",
      "[[115  18]\n",
      " [ 23  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       133\n",
      "           1       0.76      0.72      0.74        81\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.80      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n",
      "Model 5:\n",
      "Accuracy: 0.80\n",
      "[[114  19]\n",
      " [ 23  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       133\n",
      "           1       0.75      0.72      0.73        81\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.79      0.79      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluating models on sample data\n",
    "y_pred_3 = logit_3.predict(X_validate)\n",
    "y_pred_4 = logit_4.predict(X_validate)\n",
    "y_pred_5 = logit_5.predict(X_validate)\n",
    "\n",
    "# printing accuracy, confusion matrix, and classification report for model 3\n",
    "print(\"Model 3:\")\n",
    "print('Accuracy: {:.2f}'.format(logit_3.score(X_validate, y_validate)))\n",
    "print(confusion_matrix(y_validate, y_pred_3))\n",
    "print(classification_report(y_validate, y_pred_3))\n",
    "\n",
    "# printing accuracy, confusion matrix, and classification report for model 4\n",
    "print(\"Model 4:\")\n",
    "print('Accuracy: {:.2f}'.format(logit_4.score(X_validate, y_validate)))\n",
    "print(confusion_matrix(y_validate, y_pred_4))\n",
    "print(classification_report(y_validate, y_pred_4))\n",
    "\n",
    "# printing accuracy, confusion matrix, and classification report for model 5\n",
    "print(\"Model 5:\")\n",
    "print('Accuracy: {:.2f}'.format(logit_5.score(X_validate, y_validate)))\n",
    "print(confusion_matrix(y_validate, y_pred_5))\n",
    "print(classification_report(y_validate, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Model 4 is ~1% more accurate than models 3 and 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model 4 on train, validate and test data\n",
    "y_pred_4_train = logit_4.predict(X_train)\n",
    "y_pred_4_val = logit_4.predict(X_validate)\n",
    "y_pred_4_test = logit_4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Model 4 applied to train data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       302\n",
      "           1       0.72      0.68      0.70       196\n",
      "\n",
      "    accuracy                           0.77       498\n",
      "   macro avg       0.76      0.75      0.76       498\n",
      "weighted avg       0.77      0.77      0.77       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report for model 4 vs train data \n",
    "print('Classification report of Model 4 applied to train data\\n')\n",
    "print(classification_report(y_train, y_pred_4_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Model 4 applied to validate data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       133\n",
      "           1       0.76      0.72      0.74        81\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.80      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report for model 4 vs validate data \n",
    "print('Classification report of Model 4 applied to validate data\\n')\n",
    "print(classification_report(y_validate, y_pred_4_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Model 4 applied to test data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       114\n",
      "           1       0.73      0.71      0.72        65\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report for model 4 vs test data \n",
    "print('Classification report of Model 4 applied to test data\\n')\n",
    "print(classification_report(y_test, y_pred_4_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Model 4 showcased higher accuracy when applied to the validate and test data than it did when\n",
    "# it was applied to the train data. Overall it had the highest accuracy on the validate data set. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
