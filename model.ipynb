{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>categorical_sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S   \n",
       "1         1       1  female  38.0      1      0  71.2833        C   \n",
       "2         1       3  female  26.0      0      0   7.9250        S   \n",
       "3         1       1  female  35.0      1      0  53.1000        S   \n",
       "4         0       3    male  35.0      0      0   8.0500        S   \n",
       "\n",
       "   embark_town  alone  categorical_sex  \n",
       "0            2      0                1  \n",
       "1            0      0                0  \n",
       "2            2      1                0  \n",
       "3            2      0                0  \n",
       "4            2      1                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from acquire import new_get_titanic_data\n",
    "from titanic_model_setup import prep_titanic\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# using functions from prep and aqcuire to create titanic dataframe\n",
    "# PLEASE NOTE: a new prep file was created for this exercise in order to avoid altering the\n",
    "# contents of the original file (as their requirements differ slighltly)\n",
    "# new file is named 'titanic_model_setup'\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "\n",
    "# display first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 2) , X_validate:  (214, 2) , X_test:  (179, 2)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "X = df[['pclass','fare']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by dropping rows\n",
    "\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by defining your baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    302\n",
       "1    196\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with class to use for baseline\n",
    "# 0 = did not survive | 1 = survived\n",
    "# since there are less survivors than deceased, not survived will be baseline\n",
    "y_train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline\n",
       "689       1         0\n",
       "84        1         0\n",
       "738       0         0\n",
       "441       0         0\n",
       "643       1         0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe using y_train (survived) data\n",
    "models = pd.DataFrame(y_train)\n",
    "# adding column that will hold baseline values (0)\n",
    "models['baseline'] = 0\n",
    "# renaming first column\n",
    "models.columns = ['actual','baseline']\n",
    "# displaying results\n",
    "models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model is 61.0% accurate\n"
     ]
    }
   ],
   "source": [
    "# calculating baseline accuracy via creating boolean mask that holds true for rows where the \n",
    "# baseline matches the actual value\n",
    "# mean tells use the % of rows where this occured, ie. % of rows where baseline model was correct\n",
    "baseline_accuracy = (models.baseline == models.actual).mean()\n",
    "\n",
    "# printing results, baseline had accuracy of 61%\n",
    "print(f'The baseline model is {round(baseline_accuracy,2) * 100}% accurate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create another model that includes age in addition to fare and pclass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 3) , X_validate:  (214, 3) , X_test:  (179, 3)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "# adding age this time\n",
    "X = df[['pclass','fare', 'age']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating logistic regression object\n",
    "logit_1 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training data\n",
    "logit_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.94438149  0.00314466 -0.02819317]]\n",
      "Intercept: \n",
      " [2.41877072]\n"
     ]
    }
   ],
   "source": [
    "# printing model coefficients and intercept \n",
    "print('Coefficient: \\n', logit_1.coef_)\n",
    "print('Intercept: \\n', logit_1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate whether or not a person would survive based on the training data\n",
    "y_pred = logit_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p of person surviving\n",
    "y_pred_proba = logit_1.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259  43]\n",
      " [101  95]]\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78       302\n",
      "           1       0.69      0.48      0.57       196\n",
      "\n",
      "    accuracy                           0.71       498\n",
      "   macro avg       0.70      0.67      0.68       498\n",
      "weighted avg       0.71      0.71      0.70       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report to see details of model performance\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does this model perform better than your previous one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Yes, this model has an accuracy of 71%, this is 10% higher than the baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 4) , X_validate:  (214, 4) , X_test:  (179, 4)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "# adding age and sex this time\n",
    "X = df[['pclass','fare', 'age', 'categorical_sex']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# importing imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating logistic regression object\n",
    "logit_2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training data\n",
    "logit_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.12616011e+00  1.32701409e-04 -2.12849959e-02 -2.39973517e+00]]\n",
      "Intercept: \n",
      " [4.18183443]\n"
     ]
    }
   ],
   "source": [
    "# printing model coefficients and intercept \n",
    "print('Coefficient: \\n', logit_2.coef_)\n",
    "print('Intercept: \\n', logit_2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate whether or not a person would survive based on the training data\n",
    "y_pred = logit_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p of person surviving\n",
    "y_pred_proba = logit_2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246  56]\n",
      " [ 53 143]]\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       302\n",
      "           1       0.72      0.73      0.72       196\n",
      "\n",
      "    accuracy                           0.78       498\n",
      "   macro avg       0.77      0.77      0.77       498\n",
      "weighted avg       0.78      0.78      0.78       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report to see details of model performance\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 5) , X_validate:  (214, 5) , X_test:  (179, 5)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# declaring which columns will be included in X and y\n",
    "# adding age, sex and whether the passenger was alone this time\n",
    "X = df[['pclass','fare', 'age', 'categorical_sex', 'alone']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs using curriculum specifications\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# importing imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 3 different logistic regression objects with different solver arguments\n",
    "# Note: models 4 and 5 will be used for upcoming question # 5\n",
    "logit_3 = LogisticRegression(solver = 'lbfgs')\n",
    "logit_4 = LogisticRegression(solver = 'liblinear')\n",
    "logit_5 = LogisticRegression(solver = 'newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting models to training data \n",
    "# Note: models 4 and 5 will be used for upcoming question # 5\n",
    "logit_3.fit(X_train, y_train)\n",
    "logit_4.fit(X_train, y_train)\n",
    "logit_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.12726009e+00 -3.21796518e-04 -2.03922298e-02 -2.35677691e+00\n",
      "  -2.08399581e-01]]\n",
      "Intercept: \n",
      " [4.26875038]\n"
     ]
    }
   ],
   "source": [
    "# printing model coefficients and intercept \n",
    "print('Coefficient: \\n', logit_3.coef_)\n",
    "print('Intercept: \\n', logit_3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate whether or not a person would survive based on the training data\n",
    "y_pred = logit_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p of person surviving\n",
    "y_pred_proba = logit_3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[251  51]\n",
      " [ 56 140]]\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       302\n",
      "           1       0.73      0.71      0.72       196\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.77      0.77       498\n",
      "weighted avg       0.78      0.79      0.78       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report to see details of model performance\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3:\n",
      "Accuracy: 0.80\n",
      "[[114  19]\n",
      " [ 23  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       133\n",
      "           1       0.75      0.72      0.73        81\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.79      0.79      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n",
      "Model 4:\n",
      "Accuracy: 0.81\n",
      "[[115  18]\n",
      " [ 23  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       133\n",
      "           1       0.76      0.72      0.74        81\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.80      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n",
      "Model 5:\n",
      "Accuracy: 0.80\n",
      "[[114  19]\n",
      " [ 23  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       133\n",
      "           1       0.75      0.72      0.73        81\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.79      0.79      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluating models on sample data\n",
    "y_pred_3 = logit_3.predict(X_validate)\n",
    "y_pred_4 = logit_4.predict(X_validate)\n",
    "y_pred_5 = logit_5.predict(X_validate)\n",
    "\n",
    "# printing accuracy, confusion matrix, and classification report for model 3\n",
    "print(\"Model 3:\")\n",
    "print('Accuracy: {:.2f}'.format(logit_3.score(X_validate, y_validate)))\n",
    "print(confusion_matrix(y_validate, y_pred_3))\n",
    "print(classification_report(y_validate, y_pred_3))\n",
    "\n",
    "# printing accuracy, confusion matrix, and classification report for model 4\n",
    "print(\"Model 4:\")\n",
    "print('Accuracy: {:.2f}'.format(logit_4.score(X_validate, y_validate)))\n",
    "print(confusion_matrix(y_validate, y_pred_4))\n",
    "print(classification_report(y_validate, y_pred_4))\n",
    "\n",
    "# printing accuracy, confusion matrix, and classification report for model 5\n",
    "print(\"Model 5:\")\n",
    "print('Accuracy: {:.2f}'.format(logit_5.score(X_validate, y_validate)))\n",
    "print(confusion_matrix(y_validate, y_pred_5))\n",
    "print(classification_report(y_validate, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Model 4 is ~1% more accurate than models 3 and 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model 4 on train, validate and test data\n",
    "y_pred_4_train = logit_4.predict(X_train)\n",
    "y_pred_4_val = logit_4.predict(X_validate)\n",
    "y_pred_4_test = logit_4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Model 4 applied to train data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       302\n",
      "           1       0.72      0.68      0.70       196\n",
      "\n",
      "    accuracy                           0.77       498\n",
      "   macro avg       0.76      0.75      0.76       498\n",
      "weighted avg       0.77      0.77      0.77       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report for model 4 vs train data \n",
    "print('Classification report of Model 4 applied to train data\\n')\n",
    "print(classification_report(y_train, y_pred_4_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Model 4 applied to validate data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       133\n",
      "           1       0.76      0.72      0.74        81\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.80      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report for model 4 vs validate data \n",
    "print('Classification report of Model 4 applied to validate data\\n')\n",
    "print(classification_report(y_validate, y_pred_4_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Model 4 applied to test data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       114\n",
      "           1       0.73      0.71      0.72        65\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report for model 4 vs test data \n",
    "print('Classification report of Model 4 applied to test data\\n')\n",
    "print(classification_report(y_test, y_pred_4_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Model 4 showcased higher accuracy when applied to the validate and test data than it did when\n",
    "# it was applied to the train data. Overall it had the highest accuracy on the validate data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (498, 3) , X_validate:  (214, 3) , X_test:  (179, 3)\n",
      "y_train:  (498, 1) , y_validate:  (214, 1) , y_test:  (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "\n",
    "# declaring which columns will be included in X and y\n",
    "# adding age, sex and whether the passenger was alone this time\n",
    "X = df[['fare','categorical_sex', 'pclass']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "# printing results\n",
    "print(\"X_train: \", X_train.shape, \", X_validate: \", X_validate.shape, \", X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape, \", y_validate: \", y_validate.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing decision tree function\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# setting depth and state for function\n",
    "clf = DecisionTreeClassifier(max_depth = 1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making predictions on whether passengers survived\n",
    "y_pred_1 = clf.predict(X_train)\n",
    "y_pred_1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26404494, 0.73595506],\n",
       "       [0.26404494, 0.73595506],\n",
       "       [0.796875  , 0.203125  ],\n",
       "       [0.796875  , 0.203125  ],\n",
       "       [0.796875  , 0.203125  ]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities of survival\n",
    "y_pred_1_proba = clf.predict_proba(X_train)\n",
    "y_pred_1_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# printing accuracy of model 1\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255,  47],\n",
       "       [ 65, 131]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating confusion matrix\n",
    "confusion_matrix(y_train, y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       302\n",
      "           1       0.74      0.67      0.70       196\n",
      "\n",
      "    accuracy                           0.78       498\n",
      "   macro avg       0.77      0.76      0.76       498\n",
      "weighted avg       0.77      0.78      0.77       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report\n",
    "print(classification_report(y_train, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables for true pos, true negative, false pos, false neg\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1 is 0.7751004016064257\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Accuracy of model 1 is',accuracy) # overall accuracy, positive and negative predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall aka true positive rate of model 1 is 0.6683673469387755\n"
     ]
    }
   ],
   "source": [
    "# calculating recall\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Recall aka true positive rate of model 1 is',recall) # aka true positive rate aka sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative rate of model 1 is 0.8443708609271523\n"
     ]
    }
   ],
   "source": [
    "# calculating specificity\n",
    "specificity = tn / (tn + fp) \n",
    "\n",
    "# displaying results\n",
    "print('True negative rate of model 1 is',specificity) # aka true negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of model 1 is 0.7005347593582888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculating f score\n",
    "f1 = f1_score(y_train, y_pred_1)\n",
    "\n",
    "# displaying results\n",
    "print('F1 score of model 1 is',f1) # the mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of model 1 is 0.7359550561797753\n"
     ]
    }
   ],
   "source": [
    "# calculating precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# displaying results\n",
    "print('precision of model 1 is',precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate of model 1 is 0.15562913907284767\n"
     ]
    }
   ],
   "source": [
    "# calculating false positive rate\n",
    "fallout = fp / (fp + tn)\n",
    "\n",
    "# displaying results\n",
    "print('False positive rate of model 1 is',fallout) # false positive rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negative rate of model 1 is 0.33163265306122447\n"
     ]
    }
   ],
   "source": [
    "# calculating false negative rate\n",
    "miss_rate = fn / (fn + tp)\n",
    "\n",
    "# displaying results\n",
    "print('False negative rate of model 1 is',miss_rate) # false negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support values of model 1 are [302 196]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# calculating support in addition to other values\n",
    "p,r,f,support = precision_recall_fscore_support(y_train, y_pred_1)\n",
    "\n",
    "# displaying support\n",
    "print('support values of model 1 are',support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting depth and state for function (increasing depth to 3)\n",
    "clf = DecisionTreeClassifier(max_depth = 3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting whether each passenger survives or not\n",
    "y_pred_2 = clf.predict(X_train)\n",
    "y_pred_2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01587302, 0.98412698],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.93684211, 0.06315789],\n",
       "       [0.81699346, 0.18300654],\n",
       "       [0.81699346, 0.18300654]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of survival for each passenger\n",
    "y_pred_2_proba = clf.predict_proba(X_train)\n",
    "y_pred_2_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# printing accuracy of model 2\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[264,  38],\n",
       "       [ 67, 129]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating confusion matrix\n",
    "confusion_matrix(y_train, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       302\n",
      "           1       0.77      0.66      0.71       196\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.79      0.77      0.77       498\n",
      "weighted avg       0.79      0.79      0.79       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report\n",
    "print(classification_report(y_train, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables for true pos, true negative, false pos, false neg\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 2 is 0.7891566265060241\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Accuracy of model 2 is',accuracy) # overall accuracy, positive and negative predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall aka true positive rate of model 2 is 0.6581632653061225\n"
     ]
    }
   ],
   "source": [
    "# calculating recall\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Recall aka true positive rate of model 2 is',recall) # aka true positive rate aka sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative rate of model 2 is 0.8741721854304636\n"
     ]
    }
   ],
   "source": [
    "# calculating specificity\n",
    "specificity = tn / (tn + fp) \n",
    "\n",
    "# displaying results\n",
    "print('True negative rate of model 2 is',specificity) # aka true negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of model 2 is 0.7107438016528926\n"
     ]
    }
   ],
   "source": [
    "# calculating f score\n",
    "f1 = f1_score(y_train, y_pred_2)\n",
    "\n",
    "# displaying results\n",
    "print('F1 score of model 2 is',f1) # the mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of model 2 is 0.7724550898203593\n"
     ]
    }
   ],
   "source": [
    "# calculating precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# displaying results\n",
    "print('precision of model 2 is',precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate of model 2 is 0.12582781456953643\n"
     ]
    }
   ],
   "source": [
    "# calculating false positive rate\n",
    "fallout = fp / (fp + tn)\n",
    "\n",
    "# displaying results\n",
    "print('False positive rate of model 2 is',fallout) # false positive rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negative rate of model 2 is 0.34183673469387754\n"
     ]
    }
   ],
   "source": [
    "# calculating false negative rate\n",
    "miss_rate = fn / (fn + tp)\n",
    "\n",
    "# displaying results\n",
    "print('False negative rate of model 2 is',miss_rate) # false negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support values of model 2 are [302 196]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# calculating support in addition to other values\n",
    "p,r,f,support = precision_recall_fscore_support(y_train, y_pred_2)\n",
    "\n",
    "# displaying support\n",
    "print('support values of model 2 are',support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Model 2s accuracy was 1% higher so it performed better\n"
     ]
    }
   ],
   "source": [
    "# Answer: Model 2's accuracy was 1% higher so it performed better\n",
    "\n",
    "print('Answer: Model 2s accuracy was 1% higher so it performed better')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass   age      fare  sibsp  parch\n",
       "583       1  36.0   40.1250      0      0\n",
       "165       3   9.0   20.5250      0      2\n",
       "50        3   7.0   39.6875      4      1\n",
       "259       2  50.0   26.0000      0      1\n",
       "306       1   NaN  110.8833      0      0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "\n",
    "# setting X and Y features\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[[\"survived\"]]\n",
    "\n",
    "# splitting DF into test and train/validate\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123, stratify=y.survived)\n",
    "\n",
    "# splitting train/validate into separate train and validate DFs\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size=0.30, random_state = 123, stratify=y_train_validate)\n",
    "\n",
    "# examining a few rows of train df\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating random forest object with specified depth and min samples leaf (model 1)\n",
    "rf = RandomForestClassifier(bootstrap = True, \n",
    "                            class_weight = None, \n",
    "                            criterion = 'gini',\n",
    "                            min_samples_leaf = 1,\n",
    "                            n_estimators = 100,\n",
    "                            max_depth = 20, \n",
    "                            random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08782238 0.36894488 0.42682963 0.06658478 0.04981834]\n"
     ]
    }
   ],
   "source": [
    "# printing feature importances\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting wether each passenger would survive\n",
    "y_pred_1 = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating p of each passenger surviving\n",
    "y_pred_proba_1 = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1 on training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "# printing model score\n",
    "print('Accuracy of model 1 on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[303   4]\n",
      " [  8 183]]\n"
     ]
    }
   ],
   "source": [
    "# creating confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       307\n",
      "           1       0.98      0.96      0.97       191\n",
      "\n",
      "    accuracy                           0.98       498\n",
      "   macro avg       0.98      0.97      0.97       498\n",
      "weighted avg       0.98      0.98      0.98       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating classification report\n",
    "print(classification_report(y_train, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1 is 0.9759036144578314 \n",
      "\n",
      "Recall aka true positive rate of model 1 is 0.9581151832460733 \n",
      "\n",
      "True negative rate of model 1 is 0.9869706840390879 \n",
      "\n",
      "F1 score of model 1 is 0.9682539682539684 \n",
      "\n",
      "precision of model 1 is 0.9786096256684492 \n",
      "\n",
      "False positive rate of model 1 is 0.013029315960912053 \n",
      "\n",
      "False negative rate of model 1 is 0.041884816753926704 \n",
      "\n",
      "support values of model 1 are [307 191]\n"
     ]
    }
   ],
   "source": [
    "# setting variables for true pos, true negative, false pos, false neg\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_1).ravel()\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Accuracy of model 1 is', accuracy,'\\n') # overall accuracy, positive and negative predictions\n",
    "\n",
    "# calculating recall\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Recall aka true positive rate of model 1 is',recall,'\\n') # aka true positive rate aka sensitivity\n",
    "\n",
    "# calculating specificity\n",
    "specificity = tn / (tn + fp) \n",
    "\n",
    "# displaying results\n",
    "print('True negative rate of model 1 is',specificity,'\\n') # aka true negative rate\n",
    "\n",
    "# calculating f score\n",
    "f1 = f1_score(y_train, y_pred_1)\n",
    "\n",
    "# displaying results\n",
    "print('F1 score of model 1 is',f1,'\\n') # the mean of precision and recall\n",
    "\n",
    "# calculating precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# displaying results\n",
    "print('precision of model 1 is',precision,'\\n')\n",
    "\n",
    "# calculating false positive rate\n",
    "fallout = fp / (fp + tn)\n",
    "\n",
    "# displaying results\n",
    "print('False positive rate of model 1 is',fallout,'\\n') # false positive rate\n",
    "\n",
    "# calculating false negative rate\n",
    "miss_rate = fn / (fn + tp)\n",
    "\n",
    "# displaying results\n",
    "print('False negative rate of model 1 is',miss_rate,'\\n') # false negative rate\n",
    "\n",
    "# calculating support in addition to other values\n",
    "p,r,f,support = precision_recall_fscore_support(y_train, y_pred_1)\n",
    "\n",
    "# displaying support\n",
    "print('support values of model 1 are',support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating random forest object with depth 3 and min samples leaf of 5 (model 2)\n",
    "rf2 = RandomForestClassifier(bootstrap = True, \n",
    "                            class_weight = None, \n",
    "                            criterion = 'gini',\n",
    "                            min_samples_leaf = 5,\n",
    "                            n_estimators = 100,\n",
    "                            max_depth = 3, \n",
    "                            random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=3, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training data\n",
    "rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28927847 0.16919982 0.37805494 0.11157186 0.05189491]\n"
     ]
    }
   ],
   "source": [
    "# printing feature importances\n",
    "print(rf2.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting wether each passenger would survive\n",
    "y_pred_2 = rf2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating p of each passenger surviving\n",
    "y_pred_proba_2 = rf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.73\n"
     ]
    }
   ],
   "source": [
    "# printing model score\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[303   4]\n",
      " [  8 183]]\n"
     ]
    }
   ],
   "source": [
    "# creating confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       307\n",
      "           1       0.98      0.96      0.97       191\n",
      "\n",
      "    accuracy                           0.98       498\n",
      "   macro avg       0.98      0.97      0.97       498\n",
      "weighted avg       0.98      0.98      0.98       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating classification report\n",
    "print(classification_report(y_train, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 2 is 0.7349397590361446 \n",
      "\n",
      "Recall aka true positive rate of model 2 is 0.5602094240837696 \n",
      "\n",
      "True negative rate of model 2 is 0.8436482084690554 \n",
      "\n",
      "F1 score of model 2 is 0.6184971098265897 \n",
      "\n",
      "precision of model 2 is 0.6903225806451613 \n",
      "\n",
      "False positive rate of model 2 is 0.1563517915309446 \n",
      "\n",
      "False negative rate of model 2 is 0.4397905759162304 \n",
      "\n",
      "support values of model 2 are [307 191]\n"
     ]
    }
   ],
   "source": [
    "# setting variables for true pos, true negative, false pos, false neg\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_2).ravel()\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Accuracy of model 2 is', accuracy,'\\n') # overall accuracy, positive and negative predictions\n",
    "\n",
    "# calculating recall\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "# displaying results\n",
    "print('Recall aka true positive rate of model 2 is',recall,'\\n') # aka true positive rate aka sensitivity\n",
    "\n",
    "# calculating specificity\n",
    "specificity = tn / (tn + fp) \n",
    "\n",
    "# displaying results\n",
    "print('True negative rate of model 2 is',specificity,'\\n') # aka true negative rate\n",
    "\n",
    "# calculating f score\n",
    "f1 = f1_score(y_train, y_pred_2)\n",
    "\n",
    "# displaying results\n",
    "print('F1 score of model 2 is',f1,'\\n') # the mean of precision and recall\n",
    "\n",
    "# calculating precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# displaying results\n",
    "print('precision of model 2 is',precision,'\\n')\n",
    "\n",
    "# calculating false positive rate\n",
    "fallout = fp / (fp + tn)\n",
    "\n",
    "# displaying results\n",
    "print('False positive rate of model 2 is',fallout,'\\n') # false positive rate\n",
    "\n",
    "# calculating false negative rate\n",
    "miss_rate = fn / (fn + tp)\n",
    "\n",
    "# displaying results\n",
    "print('False negative rate of model 2 is',miss_rate,'\\n') # false negative rate\n",
    "\n",
    "# calculating support in addition to other values\n",
    "p,r,f,support = precision_recall_fscore_support(y_train, y_pred_2)\n",
    "\n",
    "# displaying support\n",
    "print('support values of model 2 are',support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the differences in the evaluation metrics? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 has accuracy ~20% higher, recall ~50% higher, precision ~20% higher\n"
     ]
    }
   ],
   "source": [
    "# model 1 has accuracy ~20% higher, recall ~50% higher, precision ~20% higher\n",
    "print('model 1 has accuracy ~20% higher, recall ~50% higher, precision ~20% higher')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1 performs better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1 has a very high max depth of 20. This means that its probably overfitted for the data and although\n",
    "# it performs well on train (the sample its overfitted on), it will perform poorly on an out of sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 3 on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "# creating random forest object with depth 1 and min samples leaf of 4 (model 3)\n",
    "rf3 = RandomForestClassifier(bootstrap = True, \n",
    "                            class_weight = None, \n",
    "                            criterion = 'gini',\n",
    "                            min_samples_leaf = 5,\n",
    "                            n_estimators = 100,\n",
    "                            max_depth = 10, \n",
    "                            random_state = 123)\n",
    "\n",
    "# fitting model 3 to training data\n",
    "rf3.fit(X_train, y_train)\n",
    "\n",
    "# predicting wether each passenger would survive\n",
    "y_pred_3 = rf3.predict(X_train)\n",
    "\n",
    "# printing model score\n",
    "print('Accuracy of model 3 on training set: {:.2f}'\n",
    "     .format(rf3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 4 on training set: 0.75\n"
     ]
    }
   ],
   "source": [
    "# creating random forest object with depth 1 and min samples leaf of 4 (model 4)\n",
    "rf4 = RandomForestClassifier(bootstrap = True, \n",
    "                            class_weight = None, \n",
    "                            criterion = 'gini',\n",
    "                            min_samples_leaf = 10,\n",
    "                            n_estimators = 100,\n",
    "                            max_depth = 5, \n",
    "                            random_state = 123)\n",
    "\n",
    "# fitting model 3 to training data\n",
    "rf4.fit(X_train, y_train)\n",
    "\n",
    "# predicting wether each passenger would survive\n",
    "y_pred_4 = rf4.predict(X_train)\n",
    "\n",
    "# printing model score\n",
    "print('Accuracy of model 4 on training set: {:.2f}'\n",
    "     .format(rf4.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample - accuracy summary\n",
      "Accuracy of model 1 on training set: 0.98\n",
      "Accuracy of model 2 on training set: 0.73\n",
      "Accuracy of model 3 on training set: 0.80\n",
      "Accuracy of model 4 on training set: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Training sample - accuracy summary')\n",
    "\n",
    "# printing accuracy of model 1 vs training sample\n",
    "print('Accuracy of model 1 on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "\n",
    "# printing accuracy of model 2 vs training sample\n",
    "print('Accuracy of model 2 on training set: {:.2f}'\n",
    "     .format(rf2.score(X_train, y_train)))\n",
    "\n",
    "# printing accuracy of model 3 vs training sample\n",
    "print('Accuracy of model 3 on training set: {:.2f}'\n",
    "     .format(rf3.score(X_train, y_train)))\n",
    "\n",
    "# printing accuracy of model 4 vs training sample\n",
    "print('Accuracy of model 4 on training set: {:.2f}'\n",
    "     .format(rf4.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate sample - accuracy summary\n",
      "Accuracy of model 1 on validateing set: 0.72\n",
      "Accuracy of model 2 on validateing set: 0.75\n",
      "Accuracy of model 3 on validateing set: 0.77\n",
      "Accuracy of model 4 on validateing set: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Validate sample - accuracy summary')\n",
    "\n",
    "# printing accuracy of model 1 vs validation \n",
    "print('Accuracy of model 1 on validation set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))\n",
    "\n",
    "# printing accuracy of model 2 vs validation \n",
    "print('Accuracy of model 2 on validation set: {:.2f}'\n",
    "     .format(rf2.score(X_validate, y_validate)))\n",
    "\n",
    "# printing accuracy of model 3 vs validation \n",
    "print('Accuracy of model 3 on validation set: {:.2f}'\n",
    "     .format(rf3.score(X_validate, y_validate)))\n",
    "\n",
    "# printing accuracy of model 4 vs validation \n",
    "print('Accuracy of model 4 on validation set: {:.2f}'\n",
    "     .format(rf4.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Model 4 had the smallest difference between its training and validate accuracy, 1%.\n"
     ]
    }
   ],
   "source": [
    "# Answer: Model 2 had the smallest difference between its training and validate accuracy (1%).\n",
    "\n",
    "print('Answer: Model 4 had the smallest difference between its training and validate accuracy, 1%.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass   age      fare  sibsp  parch\n",
       "583       1  36.0   40.1250      0      0\n",
       "165       3   9.0   20.5250      0      2\n",
       "50        3   7.0   39.6875      4      1\n",
       "259       2  50.0   26.0000      0      1\n",
       "306       1   NaN  110.8833      0      0"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "\n",
    "# setting X and Y features\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[[\"survived\"]]\n",
    "\n",
    "# splitting DF into test and train/validate\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123, stratify=y.survived)\n",
    "\n",
    "# splitting train/validate into separate train and validate DFs\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size=0.30, random_state = 123, stratify=y_train_validate)\n",
    "\n",
    "# examining a few rows of train df\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# fitting model to train sample\n",
    "knn1.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = knn1.predict(X_train)\n",
    "\n",
    "y_pred_proba = knn1.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier Model 1 on training set: 0.76\n",
      "\n",
      "Confusion Matrix of KNN Model 1\n",
      "[[251  56]\n",
      " [ 64 127]]\n",
      "\n",
      "Classification report of KNN Model 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       307\n",
      "           1       0.69      0.66      0.68       191\n",
      "\n",
      "    accuracy                           0.76       498\n",
      "   macro avg       0.75      0.74      0.74       498\n",
      "weighted avg       0.76      0.76      0.76       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing accuracy of model 1\n",
    "print('Accuracy of KNN classifier Model 1 on training set: {:.2f}'\n",
    "     .format(knn1.score(X_train, y_train)))\n",
    "\n",
    "# printing confusion matrix of model 1\n",
    "print('\\nConfusion Matrix of KNN Model 1')\n",
    "print(confusion_matrix(y_train, y_pred1))\n",
    "\n",
    "# printing classification report of model 1\n",
    "print('\\nClassification report of KNN Model 1')\n",
    "print(classification_report(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1 is 0.7590361445783133 \n",
      "\n",
      "Recall aka true positive rate of model 1 is 0.6649214659685864 \n",
      "\n",
      "True negative rate of model 1 is 0.8175895765472313 \n",
      "\n",
      "F1 score of model 1 is 0.9682539682539684 \n",
      "\n",
      "Precision of model 1 is 0.6939890710382514 \n",
      "\n",
      "False positive rate of model 1 is 0.18241042345276873 \n",
      "\n",
      "False negative rate of model 1 is 0.33507853403141363 \n",
      "\n",
      "Support values of model 1 are [307 191]\n"
     ]
    }
   ],
   "source": [
    "# setting variables for true pos, true negative, false pos, false neg\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred1).ravel()\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "# displaying results\n",
    "print('Accuracy of model 1 is', accuracy,'\\n') # overall accuracy, positive and negative predictions\n",
    "\n",
    "# calculating recall\n",
    "recall = tp / (tp + fn)\n",
    "# displaying results\n",
    "print('Recall aka true positive rate of model 1 is',recall,'\\n') # aka true positive rate aka sensitivity\n",
    "\n",
    "# calculating specificity\n",
    "specificity = tn / (tn + fp) \n",
    "# displaying results\n",
    "print('True negative rate of model 1 is',specificity,'\\n') # aka true negative rate\n",
    "\n",
    "# calculating f score\n",
    "f1 = f1_score(y_train, y_pred_1)\n",
    "# displaying results\n",
    "print('F1 score of model 1 is',f1,'\\n') # the mean of precision and recall\n",
    "\n",
    "# calculating precision\n",
    "precision = tp / (tp + fp)\n",
    "# displaying results\n",
    "print('Precision of model 1 is',precision,'\\n')\n",
    "\n",
    "# calculating false positive rate\n",
    "fallout = fp / (fp + tn)\n",
    "# displaying results\n",
    "print('False positive rate of model 1 is',fallout,'\\n') # false positive rate\n",
    "\n",
    "# calculating false negative rate\n",
    "miss_rate = fn / (fn + tp)\n",
    "# displaying results\n",
    "print('False negative rate of model 1 is',miss_rate,'\\n') # false negative rate\n",
    "\n",
    "# calculating support in addition to other values\n",
    "p,r,f,support = precision_recall_fscore_support(y_train, y_pred_1)\n",
    "# displaying support\n",
    "print('Support values of model 1 are',support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier model 2 on training set: 0.72\n",
      "\n",
      "Confusion Matrix of KNN model 2\n",
      "[[277  30]\n",
      " [108  83]]\n",
      "\n",
      "Classification report of KNN model 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       307\n",
      "           1       0.73      0.43      0.55       191\n",
      "\n",
      "    accuracy                           0.72       498\n",
      "   macro avg       0.73      0.67      0.67       498\n",
      "weighted avg       0.73      0.72      0.70       498\n",
      "\n",
      "Accuracy of model 2 is 0.7228915662650602 \n",
      "\n",
      "Recall aka true positive rate of model 2 is 0.43455497382198954 \n",
      "\n",
      "True negative rate of model 2 is 0.9022801302931596 \n",
      "\n",
      "F1 score of model 2 is 0.9682539682539684 \n",
      "\n",
      "Precision of model 2 is 0.7345132743362832 \n",
      "\n",
      "False positive rate of model 2 is 0.09771986970684039 \n",
      "\n",
      "False negative rate of model 2 is 0.5654450261780105 \n",
      "\n",
      "Support values of model 2 are [307 191]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "knn2 = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "\n",
    "# fitting model to train sample\n",
    "knn2.fit(X_train, y_train)\n",
    "\n",
    "# predicting whether each passenger survives\n",
    "y_pred2 = knn2.predict(X_train)\n",
    "\n",
    "# p of each passenger surviving \n",
    "y_pred_proba = knn2.predict_proba(X_train)\n",
    "\n",
    "# printing accuracy of model 2\n",
    "print('Accuracy of KNN classifier model 2 on training set: {:.2f}'\n",
    "     .format(knn2.score(X_train, y_train)))\n",
    "\n",
    "# printing confusion matrix of model 2\n",
    "print('\\nConfusion Matrix of KNN model 2')\n",
    "print(confusion_matrix(y_train, y_pred2))\n",
    "\n",
    "# printing classification report of model 2\n",
    "print('\\nClassification report of KNN model 2')\n",
    "print(classification_report(y_train, y_pred2))\n",
    "\n",
    "# setting variables for true pos, true negative, false pos, false neg\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred2).ravel()\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "# displaying results\n",
    "print('Accuracy of model 2 is', accuracy,'\\n') # overall accuracy, positive and negative predictions\n",
    "\n",
    "# calculating recall\n",
    "recall = tp / (tp + fn)\n",
    "# displaying results\n",
    "print('Recall aka true positive rate of model 2 is',recall,'\\n') # aka true positive rate aka sensitivity\n",
    "\n",
    "# calculating specificity\n",
    "specificity = tn / (tn + fp) \n",
    "# displaying results\n",
    "print('True negative rate of model 2 is',specificity,'\\n') # aka true negative rate\n",
    "\n",
    "# calculating f score\n",
    "f1 = f1_score(y_train, y_pred_1)\n",
    "# displaying results\n",
    "print('F1 score of model 2 is',f1,'\\n') # the mean of precision and recall\n",
    "\n",
    "# calculating precision\n",
    "precision = tp / (tp + fp)\n",
    "# displaying results\n",
    "print('Precision of model 2 is',precision,'\\n')\n",
    "\n",
    "# calculating false positive rate\n",
    "fallout = fp / (fp + tn)\n",
    "# displaying results\n",
    "print('False positive rate of model 2 is',fallout,'\\n') # false positive rate\n",
    "\n",
    "# calculating false negative rate\n",
    "miss_rate = fn / (fn + tp)\n",
    "# displaying results\n",
    "print('False negative rate of model 2 is',miss_rate,'\\n') # false negative rate\n",
    "\n",
    "# calculating support in addition to other values\n",
    "p,r,f,support = precision_recall_fscore_support(y_train, y_pred_1)\n",
    "# displaying support\n",
    "print('Support values of model 2 are',support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier model 3 on training set: 0.71\n",
      "\n",
      "Confusion Matrix of KNN model 3\n",
      "[[277  30]\n",
      " [115  76]]\n",
      "\n",
      "Classification report of KNN model 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       307\n",
      "           1       0.72      0.40      0.51       191\n",
      "\n",
      "    accuracy                           0.71       498\n",
      "   macro avg       0.71      0.65      0.65       498\n",
      "weighted avg       0.71      0.71      0.68       498\n",
      "\n",
      "Accuracy of model 3 is 0.7088353413654619 \n",
      "\n",
      "Recall aka true positive rate of model 3 is 0.39790575916230364 \n",
      "\n",
      "True negative rate of model 3 is 0.9022801302931596 \n",
      "\n",
      "F1 score of model 3 is 0.9682539682539684 \n",
      "\n",
      "Precision of model 3 is 0.7169811320754716 \n",
      "\n",
      "False positive rate of model 3 is 0.09771986970684039 \n",
      "\n",
      "False negative rate of model 3 is 0.6020942408376964 \n",
      "\n",
      "Support values of model 3 are [307 191]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "knn3 = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "\n",
    "# fitting model to train sample\n",
    "knn3.fit(X_train, y_train)\n",
    "\n",
    "# predicting whether each passenger survives\n",
    "y_pred3 = knn3.predict(X_train)\n",
    "\n",
    "# p of each passenger surviving \n",
    "y_pred_proba = knn3.predict_proba(X_train)\n",
    "\n",
    "# printing accuracy of model 3\n",
    "print('Accuracy of KNN classifier model 3 on training set: {:.2f}'\n",
    "     .format(knn3.score(X_train, y_train)))\n",
    "\n",
    "# printing confusion matrix of model 3\n",
    "print('\\nConfusion Matrix of KNN model 3')\n",
    "print(confusion_matrix(y_train, y_pred3))\n",
    "\n",
    "# printing classification report of model 3\n",
    "print('\\nClassification report of KNN model 3')\n",
    "print(classification_report(y_train, y_pred3))\n",
    "\n",
    "# setting variables for true pos, true negative, false pos, false neg\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred3).ravel()\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "# displaying results\n",
    "print('Accuracy of model 3 is', accuracy,'\\n') # overall accuracy, positive and negative predictions\n",
    "\n",
    "# calculating recall\n",
    "recall = tp / (tp + fn)\n",
    "# displaying results\n",
    "print('Recall aka true positive rate of model 3 is',recall,'\\n') # aka true positive rate aka sensitivity\n",
    "\n",
    "# calculating specificity\n",
    "specificity = tn / (tn + fp) \n",
    "# displaying results\n",
    "print('True negative rate of model 3 is',specificity,'\\n') # aka true negative rate\n",
    "\n",
    "# calculating f score\n",
    "f1 = f1_score(y_train, y_pred_1)\n",
    "# displaying results\n",
    "print('F1 score of model 3 is',f1,'\\n') # the mean of precision and recall\n",
    "\n",
    "# calculating precision\n",
    "precision = tp / (tp + fp)\n",
    "# displaying results\n",
    "print('Precision of model 3 is',precision,'\\n')\n",
    "\n",
    "# calculating false positive rate\n",
    "fallout = fp / (fp + tn)\n",
    "# displaying results\n",
    "print('False positive rate of model 3 is',fallout,'\\n') # false positive rate\n",
    "\n",
    "# calculating false negative rate\n",
    "miss_rate = fn / (fn + tp)\n",
    "# displaying results\n",
    "print('False negative rate of model 3 is',miss_rate,'\\n') # false negative rate\n",
    "\n",
    "# calculating support in addition to other values\n",
    "p,r,f,support = precision_recall_fscore_support(y_train, y_pred_1)\n",
    "# displaying support\n",
    "print('Support values of model 3 are',support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the differences in the evaluation metrics? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 models have similar accuracy (70-75%)\n",
      "With regard to recall, models 2 and 3 are around 40% while model 1 has 66%\n",
      "All 3 have similar F1 scores (~96%)\n",
      "All 3 have similar precision (70-73%\n"
     ]
    }
   ],
   "source": [
    "print('All 3 models have similar accuracy (70-75%)')\n",
    "print('With regard to recall, models 2 and 3 are around 40% while model 1 has 66%')\n",
    "print('All 3 have similar F1 scores (~96%)')\n",
    "print('All 3 have similar precision (70-73%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which performs better on your in-sample data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 performs the best because it has similar metrics to the other 2 models while having a recall rate that is ~22% higher\n"
     ]
    }
   ],
   "source": [
    "print('Model 1 performs the best because it has similar metrics to the other 2 models while having a recall rate that is ~22% higher')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 has the highest recall because it had the lowest rate of false positives. We can reason that this was due to its neighbor count being lower than the others.\n"
     ]
    }
   ],
   "source": [
    "print('Model 1 has the highest recall because it had the lowest rate of false positives. We can reason that this was due to its neighbor count being lower than the others.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine which model (with hyperparameters) performs the best (try reducing the number of features to the top 4 features in terms of information gained for each feature individually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "\n",
    "# declaring which columns will be included in X and y\n",
    "X = df[['pclass','fare', 'age', 'categorical_sex']]\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier model 1 on training set: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Creating / fitting model 1\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# fitting model to train sample\n",
    "knn1.fit(X_train, y_train)\n",
    "\n",
    "# using model to make predictions of survival using X_train data\n",
    "y_pred1 = knn1.predict(X_train)\n",
    "\n",
    "model1_acc = round(knn1.score(X_train, y_train),2)\n",
    "\n",
    "# printing accuracy of model 1\n",
    "print('Accuracy of KNN classifier model 1 on training set:', model1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier model 2 on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Creating / fitting model 2\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "knn2 = KNeighborsClassifier(n_neighbors=10, algorithm = 'ball_tree', weights='uniform')\n",
    "\n",
    "# fitting model to train sample\n",
    "knn2.fit(X_train, y_train)\n",
    "\n",
    "# using model to make predictions of survival using X_train data\n",
    "y_pred2 = knn2.predict(X_train)\n",
    "\n",
    "# printing accuracy of model 2\n",
    "print('Accuracy of KNN classifier model 2 on training set: {:.2f}'\n",
    "     .format(knn2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier model 3 on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Creating / fitting model 3\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "knn3 = KNeighborsClassifier(n_neighbors=10, algorithm = 'ball_tree', leaf_size = 5, weights='uniform')\n",
    "\n",
    "# fitting model to train sample\n",
    "knn3.fit(X_train, y_train)\n",
    "\n",
    "# using model to make predictions of survival using X_train data\n",
    "y_pred3 = knn3.predict(X_train)\n",
    "\n",
    "\n",
    "# printing accuracy of model 2\n",
    "print('Accuracy of KNN classifier model 3 on training set: {:.2f}'\n",
    "     .format(knn3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 performs the best with an accuracy of 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Model 1 performs the best with an accuracy of', model1_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new dataframe with top 4 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>fare</th>\n",
       "      <th>age</th>\n",
       "      <th>categorical_sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass     fare   age  categorical_sex\n",
       "0         3   7.2500  22.0                1\n",
       "1         1  71.2833  38.0                0\n",
       "2         3   7.9250  26.0                0\n",
       "3         1  53.1000  35.0                0\n",
       "4         3   8.0500  35.0                1\n",
       "..      ...      ...   ...              ...\n",
       "886       2  13.0000  27.0                1\n",
       "887       1  30.0000  19.0                0\n",
       "888       3  23.4500   NaN                0\n",
       "889       1  30.0000  26.0                1\n",
       "890       3   7.7500  32.0                1\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data\n",
    "four_feat_df = df[['pclass','fare', 'age', 'categorical_sex']]\n",
    "\n",
    "four_feat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the top performing algorithm with the metaparameters used in that model. Create the object, fit, transform on in-sample data, and evaluate the results with the training data. Compare your evaluation metrics with those from the original model (with all the features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "\n",
    "# declaring which columns will be included in X and y\n",
    "X = df.drop(columns = ['survived','sex','embarked'])\n",
    "\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs \n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all 3 DFs with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])\n",
    "X_validate[['age']] = imputer.transform(X_validate[['age']])\n",
    "X_test[['age']] = imputer.transform(X_test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier model 1 on training set: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Creating / fitting model 1 to new data frame \n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "knn1_new = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# fitting model to train sample\n",
    "knn1_new.fit(X_train, y_train)\n",
    "\n",
    "# using model to make predictions of survival using X_train data\n",
    "y_pred1 = knn1_new.predict(X_train)\n",
    "\n",
    "# saving new model's accuracy\n",
    "knn1_new_acc = round(knn1_new.score(X_train, y_train),2)\n",
    "\n",
    "# printing accuracy of new model 1\n",
    "print('Accuracy of KNN classifier model 1 on training set:', knn1_new_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of model 1 using top 4 features: 0.77\n",
      "accuracy of model using model 1's hyperparameters and all features: 0.76\n"
     ]
    }
   ],
   "source": [
    "# printing accuracy of model with top 4 features\n",
    "print('accuracy of model 1 using top 4 features:', model1_acc)\n",
    "\n",
    "# printing accuracy of model with all features and hyperparameters of previous model\n",
    "print('accuracy of model using model 1\\'s hyperparameters and all features:', knn1_new_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run your final model on your out-of-sample dataframe (test_df). Evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model's accuracy on test data 0.66\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy of final model on test data\n",
    "final_model_acc = round(knn1_new.score(X_test, y_test),2)\n",
    "\n",
    "# displaying results\n",
    "print(\"Final model's accuracy on test data\", final_model_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a feature named who, this should be either man, woman, or child. How does including this feature affect your model's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = prep_titanic(new_get_titanic_data())\n",
    "X = df.drop(columns = ['survived', 'embarked'])\n",
    "y = df[['survived']]\n",
    "\n",
    "# creating test, validate and train DFs \n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size = .20, random_state = 123)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size = .30, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to handle empty values in age by imputing with the most common age\n",
    "\n",
    "# setting imputer startegy to imput most frequent value\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# transforming all train DF with the fit from train\n",
    "X_train[['age']] = imputer.fit_transform(X_train[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new column 'who' that holds a number value based on men, women, and children\n",
    "X_train['who'] = X_train['age']\n",
    "X_train.loc[((X_train.age > 17) & (X_train.sex == 'male')),'who'] = 1\n",
    "X_train.loc[((X_train.age > 17) & (X_train.sex == 'female')),'who'] = 2\n",
    "X_train.loc[(X_train.age <= 17),'who'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kept losing my who column if i dropped sex column so i'm creating a new dataframe with specified columns\n",
    "# as work around\n",
    "new_X_train = X_train[['pclass','age','sibsp','parch','fare','embark_town','alone','categorical_sex','who']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier with who column on training set: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Creating model from new data frame \n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_who = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# fitting model to train sample\n",
    "knn_who.fit(new_X_train, y_train)\n",
    "\n",
    "# using model to make predictions of survival using train data\n",
    "y_pred_who = knn_who.predict(new_X_train)\n",
    "\n",
    "# saving new model's accuracy\n",
    "knn_who_acc = round(knn_who.score(new_X_train, y_train),2)\n",
    "\n",
    "# printing accuracy of new model 1\n",
    "print('Accuracy of KNN classifier with who column on training set:', knn_who_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a feature named adult_male that is either a 1 or a 0. How does this affect your model's predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new column 'adult_male' that holds a 1 if person is adult male, 0 otherwise\n",
    "new_X_train['adult_male'] = 0\n",
    "new_X_train.loc[(new_X_train.who == 1,'adult_male')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier with adult_male column on training set: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Creating model from new data frame \n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_AM = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# fitting model to train sample\n",
    "knn_AM.fit(new_X_train, y_train)\n",
    "\n",
    "# using model to make predictions of survival using train data\n",
    "y_pred_who = knn_AM.predict(new_X_train)\n",
    "\n",
    "# saving new model's accuracy\n",
    "knn_AM_acc = round(knn_AM.score(new_X_train, y_train),2)\n",
    "\n",
    "# printing accuracy of new model 1\n",
    "print('Accuracy of KNN classifier with adult_male column on training set:', knn_AM_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create features named petal_area and sepal_area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
